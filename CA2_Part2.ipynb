{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISS VSE CA2 Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By: Kenneth Goh (A0198544N), Raymond Ng (A0198543R), Tan Heng Han (A0198502B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import repeat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and slice videos for training\n",
    "Slice training videos into 5hz frames for model input\n",
    "Data set:\n",
    "1. Push up videos\n",
    "2. Mixture of non push up videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>data/PushUps\\v_PushUps_g01_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>data/PushUps\\v_PushUps_g01_c02.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>data/PushUps\\v_PushUps_g01_c03.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>data/PushUps\\v_PushUps_g01_c04.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>data/PushUps\\v_PushUps_g01_c05.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>data/NotPushUps\\v_PullUps_g24_c04.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>data/NotPushUps\\v_PullUps_g25_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>data/NotPushUps\\v_PullUps_g25_c02.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>data/NotPushUps\\v_PullUps_g25_c03.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>data/NotPushUps\\v_PullUps_g25_c04.avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                video_name\n",
       "0       data/PushUps\\v_PushUps_g01_c01.avi\n",
       "1       data/PushUps\\v_PushUps_g01_c02.avi\n",
       "2       data/PushUps\\v_PushUps_g01_c03.avi\n",
       "3       data/PushUps\\v_PushUps_g01_c04.avi\n",
       "4       data/PushUps\\v_PushUps_g01_c05.avi\n",
       "..                                     ...\n",
       "197  data/NotPushUps\\v_PullUps_g24_c04.avi\n",
       "198  data/NotPushUps\\v_PullUps_g25_c01.avi\n",
       "199  data/NotPushUps\\v_PullUps_g25_c02.avi\n",
       "200  data/NotPushUps\\v_PullUps_g25_c03.avi\n",
       "201  data/NotPushUps\\v_PullUps_g25_c04.avi\n",
       "\n",
       "[202 rows x 1 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get filenames and labels for data\n",
    "labels = ['PushUps', 'NotPushUps']\n",
    "data_path = 'data/'\n",
    "train = pd.DataFrame()\n",
    "filenames = []\n",
    "for lbl in labels:\n",
    "    filename = np.array(glob(os.path.join(data_path, lbl) + '/*.avi'))\n",
    "    filenames.append(filename)\n",
    "\n",
    "train['video_name'] = [item for sublist in filenames for item in sublist]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 202/202 [00:36<00:00,  5.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Slice and store the frames from training videos\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = train['video_name'][i]\n",
    "    cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % 2 == 0):\n",
    "            # storing the frames in a new folder named train_1\n",
    "            filename ='data/images/' + videoFile.split('\\\\')[1] +\"_frame%d.jpg\" % count;count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OpenPose models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions to get openpose models\n",
    "1. Clone https://github.com/CMU-Perceptual-Computing-Lab/openpose\n",
    "2. Open a console and run **openpose/models/getModels.bat**\n",
    "3. Copy contents from **openpose/models/pose/mpi to Model/mpi** and **openpose/models/pose/coco to Model/coco**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "OPENPOSE_MODEL = 'mpi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPENPOSE_MODEL == 'coco':\n",
    "    PROTO_FILE = 'Model/pose_deploy_linevec.prototxt'\n",
    "    WEIGHTS_FILE = 'Model/pose_iter_440000.caffemodel'\n",
    "elif OPENPOSE_MODEL == 'mpi':\n",
    "    PROTO_FILE = 'Model/mpi/pose_deploy_linevec_faster_4_stages.prototxt'\n",
    "    WEIGHTS_FILE = 'Model/mpi/pose_iter_160000.caffemodel'\n",
    "else:\n",
    "    raise Exception('Open pose model not recognised, choose either mpi or coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPENPOSE_MODEL == 'coco':\n",
    "    BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                   \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                   \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "                   \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
    "    POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                   [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "                   [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "                   [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "                   [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n",
    "elif OPENPOSE_MODEL == 'mpi':\n",
    "    BODY_PARTS = {\"Head\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                  \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                  \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Chest\": 14,\n",
    "                  \"Background\": 15}\n",
    "    POSE_PAIRS = [ [\"Head\", \"Neck\"], [\"Neck\", \"RShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                   [\"RElbow\", \"RWrist\"], [\"Neck\", \"LShoulder\"], [\"LShoulder\", \"LElbow\"],\n",
    "                   [\"LElbow\", \"LWrist\"], [\"Neck\", \"Chest\"], [\"Chest\", \"RHip\"], [\"RHip\", \"RKnee\"],\n",
    "                   [\"RKnee\", \"RAnkle\"], [\"Chest\", \"LHip\"], [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"] ]\n",
    "else:\n",
    "    raise Exception('Open pose model not recognised, choose either mpi or coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load openpose model via Opencv\n",
    "try:\n",
    "    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "except:\n",
    "    raise Exception('Error reading model, check model proto and weights file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_frame_path = 'train_1'\n",
    "frame_filenames = glob(dataset_frame_path + '\\*.jpg')\n",
    "\n",
    "trainFrame = pd.DataFrame()\n",
    "trainFrame['frames'] = frame_filenames\n",
    "trainFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inWidth = 368\n",
    "inHeight = 368\n",
    "\n",
    "imgPaths = []\n",
    "for frame in trainFrame['frames']:\n",
    "    img = cv2.imread(frame)\n",
    "#     img = cv2.resize(img, (inWidth, inHeight))\n",
    "    imgPaths.append(img)\n",
    "    \n",
    "# cv2.imshow('img', imgPaths[0])\n",
    "# cv2.waitKey(3)\n",
    "\n",
    "testimg = imgPaths[0]\n",
    "frameWidth = testimg.shape[1]\n",
    "frameHeight = testimg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inBlob = cv2.dnn.blobFromImage(imgPaths[1], 1.0/255, (imgPaths[1].shape[1], imgPaths[1].shape[0]), (0,0,0), swapRB=False, crop=False)\n",
    "inBlob = cv2.dnn.blobFromImage(testimg, 1.0/255, (368, 368), (0,0,0), swapRB=False, crop=False)\n",
    "net.setInput(inBlob)\n",
    "output = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwinName=\"Pose\"\n",
    "cv2.namedWindow(kwinName, cv2.WINDOW_AUTOSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "for i in range(len(BODY_PARTS)):\n",
    "    # Slice heatmap of corresponging body's part.\n",
    "    heatMap = output[0, i, :, :]\n",
    " \n",
    "    # Originally, we try to find all the local maximums. To simplify a sample\n",
    "    # we just find a global one. However only a single pose at the same time\n",
    "    # could be detected this way.\n",
    "    _, conf, _, point = cv2.minMaxLoc(heatMap)\n",
    "    x = (frameWidth * point[0]) / output.shape[3]\n",
    "    y = (frameHeight * point[1]) / output.shape[2]\n",
    " \n",
    "    # Add a point if it's confidence is higher than threshold.\n",
    "    points.append((int(x), int(y)) if conf > 0.1 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in POSE_PAIRS:\n",
    "    partFrom = pair[0]\n",
    "    partTo = pair[1]\n",
    "    assert(partFrom in BODY_PARTS)\n",
    "    assert(partTo in BODY_PARTS)\n",
    " \n",
    "    idFrom = BODY_PARTS[partFrom]\n",
    "    idTo = BODY_PARTS[partTo]\n",
    "    if points[idFrom] and points[idTo]:\n",
    "        cv2.line(testimg, points[idFrom], points[idTo], (255, 74, 0), 3)\n",
    "        cv2.ellipse(testimg, points[idFrom], (4, 4), 0, 0, 360, (255, 255, 255), cv2.FILLED)\n",
    "        cv2.ellipse(testimg, points[idTo], (4, 4), 0, 0, 360, (255, 255, 255), cv2.FILLED)\n",
    "        cv2.putText(testimg, str(idFrom), points[idFrom], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255),2,cv2.LINE_AA)\n",
    "        cv2.putText(testimg, str(idTo), points[idTo], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255),2,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(kwinName, testimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
